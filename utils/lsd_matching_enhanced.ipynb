{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c21c7bbc",
   "metadata": {},
   "source": [
    "# Enhanced LSD Line Matching with Multi-Scale and Color Augmentation\n",
    "\n",
    "This notebook demonstrates an enhanced approach to line segment detection and matching using LSD (Line Segment Detector) and Binary Descriptors in OpenCV.\n",
    "It incorporates several improvements over basic LSD matching:\n",
    "- **Multi-Scale Template Processing**: The template image is processed at multiple scales (0.7x, 1.0x, 1.3x) to handle variations in object size.\n",
    "- **Color Augmentation**: HSV color histograms are extracted along detected line segments and appended to their binary descriptors, providing richer feature information.\n",
    "- **Geometric Filtering**: Matches are refined using geometric consistency checks, including angle similarity and line length ratios.\n",
    "- **Descriptor Optimization**: LSD detection uses 3 octaves, and Binary Descriptors are computed with a wider band width (9px) for more contextual information.\n",
    "- **Robust Matching**: An adaptive approach to find the best matches by considering scores from different template scales and applying geometric verification.\n",
    "\n",
    "This notebook adapts logic from the original `lsd_matching.ipynb` and incorporates concepts from the provided reference Python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86669498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d44e2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parameters ---\n",
    "\n",
    "# Image Paths\n",
    "template_base_folder = \"/Users/frbuccoliero/Desktop/Thesis/Tests/utils/wikiCommonsOutput/png/\"\n",
    "reference_image_path = \"/Users/frbuccoliero/Desktop/Thesis/Tests/template_matching/dataset/images/positive/positive_00000.jpg\"\n",
    "template_image_path = None # Will be selected from the folder\n",
    "\n",
    "# Multi-Scale Processing\n",
    "TEMPLATE_SCALES = [0.7, 1.0, 1.3]\n",
    "\n",
    "# LSD Detector Parameters\n",
    "LSD_INTERNAL_SCALE_FACTOR = 2  # Internal scale factor for LSD algorithm\n",
    "LSD_NUM_OCTAVES = 3          # Number of octaves for multi-octave detection\n",
    "\n",
    "# Binary Descriptor Parameters\n",
    "BD_BAND_WIDTH = 9            # Width of the band for descriptor computation\n",
    "\n",
    "# Matching and Filtering Parameters\n",
    "MATCHES_DIST_THRESHOLD = 50.0 # Initial Hamming distance threshold for potential matches\n",
    "ANGLE_TOLERANCE_DEG = 15.0    # Angle tolerance for geometric filtering (degrees)\n",
    "LENGTH_RATIO_MIN = 0.7        # Minimum length ratio for geometric filtering\n",
    "LENGTH_RATIO_MAX = 1.3        # Maximum length ratio for geometric filtering\n",
    "\n",
    "# Visualization\n",
    "MAX_MATCHES_TO_DISPLAY = 50   # Max matches to show in plots\n",
    "\n",
    "# Select a template image (e.g., the 9th one as in the original notebook)\n",
    "if os.path.exists(template_base_folder) and os.path.isdir(template_base_folder):\n",
    "    potential_templates = sorted([\n",
    "        os.path.join(template_base_folder, f)\n",
    "        for f in os.listdir(template_base_folder)\n",
    "        if f.lower().endswith(\".png\")\n",
    "    ])\n",
    "    if potential_templates and len(potential_templates) > 8:\n",
    "        template_image_path = potential_templates[8]\n",
    "        print(f\"Using template image: {template_image_path}\")\n",
    "    elif potential_templates:\n",
    "        template_image_path = potential_templates[0] # Fallback to the first one\n",
    "        print(f\"Fewer than 9 templates, using first one: {template_image_path}\")\n",
    "    else:\n",
    "        print(f\"No PNG template images found in {template_base_folder}. Please set 'template_image_path' manually.\")\n",
    "else:\n",
    "    print(f\"Template folder '{template_base_folder}' does not exist. Please set 'template_image_path' manually.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfca791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Images ---\n",
    "\n",
    "img1_orig = None  # Template\n",
    "img2_orig = None  # Reference\n",
    "img1_gray = None\n",
    "img2_gray = None\n",
    "\n",
    "if template_image_path and os.path.exists(template_image_path):\n",
    "    img1_orig = cv2.imread(template_image_path)\n",
    "    if img1_orig is not None:\n",
    "        img1_gray = cv2.cvtColor(img1_orig, cv2.COLOR_BGR2GRAY)\n",
    "        print(f\"Template image '{os.path.basename(template_image_path)}' loaded successfully.\")\n",
    "    else:\n",
    "        print(f\"Error loading template image: {template_image_path}\")\n",
    "else:\n",
    "    print(f\"Template image path is not valid or not set: {template_image_path}\")\n",
    "\n",
    "if os.path.exists(reference_image_path):\n",
    "    img2_orig = cv2.imread(reference_image_path)\n",
    "    if img2_orig is not None:\n",
    "        img2_gray = cv2.cvtColor(img2_orig, cv2.COLOR_BGR2GRAY)\n",
    "        print(f\"Reference image '{os.path.basename(reference_image_path)}' loaded successfully.\")\n",
    "    else:\n",
    "        print(f\"Error loading reference image: {reference_image_path}\")\n",
    "else:\n",
    "    print(f\"Reference image path does not exist: {reference_image_path}\")\n",
    "\n",
    "if img1_gray is None or img2_gray is None:\n",
    "    print(\"One or both images could not be loaded. Halting execution.\")\n",
    "    # In a real script, you might raise an error or exit here.\n",
    "else:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(cv2.cvtColor(img1_orig, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Template: {os.path.basename(template_image_path)}\")\n",
    "    plt.axis('off')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(cv2.cvtColor(img2_orig, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Reference: {os.path.basename(reference_image_path)}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e664cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Functions ---\n",
    "\n",
    "def rescale_image(image, scale):\n",
    "    \"\"\"Rescales an image by a given factor.\"\"\"\n",
    "    if scale == 1.0:\n",
    "        return image.copy()\n",
    "    width = int(image.shape[1] * scale)\n",
    "    height = int(image.shape[0] * scale)\n",
    "    dim = (width, height)\n",
    "    return cv2.resize(image, dim, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def get_line_points(keyline, num_samples=10):\n",
    "    \"\"\"Generates sample points along a line segment (KeyLine).\"\"\"\n",
    "    x0, y0 = keyline.startPointX, keyline.startPointY\n",
    "    x1, y1 = keyline.endPointX, keyline.endPointY\n",
    "    \n",
    "    xs = np.linspace(x0, x1, num_samples, dtype=int)\n",
    "    ys = np.linspace(y0, y1, num_samples, dtype=int)\n",
    "    \n",
    "    # Ensure points are within image bounds (caller should handle this if image is passed)\n",
    "    # For simplicity, we just return the points here.\n",
    "    return np.vstack((xs, ys)).T\n",
    "\n",
    "def compute_color_descriptors(image_bgr, keylines, num_hist_bins=8):\n",
    "    \"\"\"Computes HSV color histograms along line segments.\"\"\"\n",
    "    if not keylines or len(keylines) == 0:\n",
    "        return np.array([], dtype=np.float32).reshape(0, num_hist_bins)\n",
    "\n",
    "    hsv_image = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2HSV)\n",
    "    h, w = hsv_image.shape[:2]\n",
    "    descriptors = []\n",
    "\n",
    "    for kl in keylines:\n",
    "        points = get_line_points(kl, num_samples=10)\n",
    "        \n",
    "        # Clip points to be within image boundaries\n",
    "        points[:, 0] = np.clip(points[:, 0], 0, w - 1)\n",
    "        points[:, 1] = np.clip(points[:, 1], 0, h - 1)\n",
    "        \n",
    "        # Sample hues\n",
    "        hues = hsv_image[points[:, 1], points[:, 0], 0] # H channel\n",
    "        \n",
    "        # Compute histogram\n",
    "        hist = cv2.calcHist([hues], [0], None, [num_hist_bins], [0, 180])\n",
    "        cv2.normalize(hist, hist, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX) # Normalize\n",
    "        descriptors.append(hist.flatten())\n",
    "        \n",
    "    return np.array(descriptors, dtype=np.float32)\n",
    "\n",
    "def filter_matches_geometrically(matches, query_keylines, template_keylines, template_scale,\n",
    "                                 angle_tolerance_deg, length_ratio_min, length_ratio_max):\n",
    "    \"\"\"Filters matches based on geometric consistency (angle and length ratio).\"\"\"\n",
    "    if not matches:\n",
    "        return []\n",
    "    \n",
    "    valid_matches = []\n",
    "    angle_tolerance_rad = np.deg2rad(angle_tolerance_deg)\n",
    "\n",
    "    for m in matches:\n",
    "        q_kl = query_keylines[m.queryIdx]\n",
    "        t_kl = template_keylines[m.trainIdx]\n",
    "\n",
    "        # 1. Angle consistency\n",
    "        # OpenCV KeyLine angle is in radians, measured from x-axis.\n",
    "        # Ensure angles are in [0, pi] or handle periodicity if they can be [-pi, pi]\n",
    "        # LSD angles are typically [0, 2pi) or similar. Let's assume they might need normalization for diff.\n",
    "        angle_q = q_kl.angle\n",
    "        angle_t = t_kl.angle\n",
    "        \n",
    "        # Normalize angle difference to be within [-pi, pi]\n",
    "        angle_diff = angle_q - angle_t\n",
    "        while angle_diff > np.pi:\n",
    "            angle_diff -= 2 * np.pi\n",
    "        while angle_diff < -np.pi:\n",
    "            angle_diff += 2 * np.pi\n",
    "        \n",
    "        if abs(angle_diff) > angle_tolerance_rad:\n",
    "            continue\n",
    "\n",
    "        # 2. Length ratio validation\n",
    "        # q_len is length in query image (original scale)\n",
    "        # t_len_scaled is length in template image (which was scaled by template_scale)\n",
    "        # Expected q_len approx. (t_len_scaled / template_scale)\n",
    "        # Ratio: q_len / (t_len_scaled / template_scale) = (q_len * template_scale) / t_len_scaled\n",
    "        q_len = q_kl.lineLength\n",
    "        t_len_scaled = t_kl.lineLength\n",
    "\n",
    "        if t_len_scaled < 1e-3: # Avoid division by zero or tiny length\n",
    "            continue\n",
    "            \n",
    "        effective_length_ratio = (q_len * template_scale) / t_len_scaled\n",
    "        \n",
    "        if not (length_ratio_min <= effective_length_ratio <= length_ratio_max):\n",
    "            continue\n",
    "            \n",
    "        valid_matches.append(m)\n",
    "    return valid_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90a5c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initialize Detectors and Matcher ---\n",
    "\n",
    "# LSD Line Segment Detector\n",
    "lsd = cv2.line_descriptor.LSDDetector.createLSDDetector()\n",
    "\n",
    "# Binary Descriptor Extractor\n",
    "bd = cv2.line_descriptor.BinaryDescriptor.createBinaryDescriptor()\n",
    "bd.setWidthOfBand(BD_BAND_WIDTH)\n",
    "\n",
    "# Binary Descriptor Matcher\n",
    "bdm = cv2.line_descriptor.BinaryDescriptorMatcher()\n",
    "\n",
    "print(\"LSD Detector, Binary Descriptor (with wider band), and Matcher initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d099f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Preprocess Template Image (Multi-Scale with Color Augmentation) ---\n",
    "\n",
    "processed_templates_data = []\n",
    "\n",
    "if img1_orig is not None:\n",
    "    print(\"Processing template image at multiple scales...\")\n",
    "    for scale_factor in TEMPLATE_SCALES:\n",
    "        print(f\"  Processing scale: {scale_factor}x\")\n",
    "        \n",
    "        # Rescale template image\n",
    "        template_scaled_bgr = rescale_image(img1_orig, scale_factor)\n",
    "        template_scaled_gray = cv2.cvtColor(template_scaled_bgr, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detect lines using LSD\n",
    "        # Note: LSD's `scale` param is different from our image `scale_factor`.\n",
    "        # It refers to the image pyramid scale within LSD.\n",
    "        keylines_raw_template = lsd.detect(template_scaled_gray, \n",
    "                                           scale=LSD_INTERNAL_SCALE_FACTOR, \n",
    "                                           numOctaves=LSD_NUM_OCTAVES)\n",
    "        \n",
    "        if not keylines_raw_template or len(keylines_raw_template) == 0:\n",
    "            print(f\"    No raw lines detected for scale {scale_factor}x.\")\n",
    "            processed_templates_data.append({\n",
    "                'scale': scale_factor,\n",
    "                'image_bgr': template_scaled_bgr,\n",
    "                'keylines': [],\n",
    "                'descriptors_enhanced': np.array([], dtype=np.float32)\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # Compute binary descriptors\n",
    "        # OpenCV's BinaryDescriptor.compute expects the image where keylines were found.\n",
    "        # The reference code passes the color image. Let's try that.\n",
    "        # If it fails, it might need template_scaled_gray.\n",
    "        # However, color descriptors are computed separately from the color image.\n",
    "        keylines_template, descs_template_binary = bd.compute(template_scaled_bgr, keylines_raw_template)\n",
    "        \n",
    "        if descs_template_binary is None or len(descs_template_binary) == 0:\n",
    "            print(f\"    No binary descriptors computed for scale {scale_factor}x.\")\n",
    "            processed_templates_data.append({\n",
    "                'scale': scale_factor,\n",
    "                'image_bgr': template_scaled_bgr,\n",
    "                'keylines': keylines_template if keylines_template is not None else [],\n",
    "                'descriptors_enhanced': np.array([], dtype=np.float32)\n",
    "            })\n",
    "            continue\n",
    "            \n",
    "        print(f\"    Scale {scale_factor}x: Detected {len(keylines_raw_template)} raw lines. Computed {len(descs_template_binary)} binary descriptors for {len(keylines_template)} lines.\")\n",
    "\n",
    "        # Compute color descriptors\n",
    "        descs_template_color = compute_color_descriptors(template_scaled_bgr, keylines_template)\n",
    "        print(f\"    Scale {scale_factor}x: Computed {len(descs_template_color)} color descriptors.\")\n",
    "\n",
    "        # Augment descriptors (hstack requires float type for binary descriptors)\n",
    "        descs_template_enhanced = np.hstack((descs_template_binary.astype(np.float32), descs_template_color))\n",
    "        \n",
    "        processed_templates_data.append({\n",
    "            'scale': scale_factor,\n",
    "            'image_bgr': template_scaled_bgr, # Store scaled BGR image for visualization\n",
    "            'keylines': keylines_template,\n",
    "            'descriptors_enhanced': descs_template_enhanced\n",
    "        })\n",
    "    print(\"Finished processing template scales.\")\n",
    "else:\n",
    "    print(\"Template image (img1_orig) not loaded. Skipping template processing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7b9c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Process Reference Image (with Color Augmentation) ---\n",
    "\n",
    "keylines_ref = None\n",
    "descs_ref_enhanced = None\n",
    "\n",
    "if img2_gray is not None and img2_orig is not None:\n",
    "    print(\"Processing reference image...\")\n",
    "    # Detect lines using LSD\n",
    "    keylines_raw_ref = lsd.detect(img2_gray, \n",
    "                                  scale=LSD_INTERNAL_SCALE_FACTOR, \n",
    "                                  numOctaves=LSD_NUM_OCTAVES)\n",
    "\n",
    "    if keylines_raw_ref and len(keylines_raw_ref) > 0:\n",
    "        # Compute binary descriptors\n",
    "        keylines_ref, descs_ref_binary = bd.compute(img2_orig, keylines_raw_ref) # Using color image as per template processing\n",
    "\n",
    "        if descs_ref_binary is not None and len(descs_ref_binary) > 0:\n",
    "            print(f\"  Reference: Detected {len(keylines_raw_ref)} raw lines. Computed {len(descs_ref_binary)} binary descriptors for {len(keylines_ref)} lines.\")\n",
    "            \n",
    "            # Compute color descriptors\n",
    "            descs_ref_color = compute_color_descriptors(img2_orig, keylines_ref)\n",
    "            print(f\"  Reference: Computed {len(descs_ref_color)} color descriptors.\")\n",
    "\n",
    "            # Augment descriptors\n",
    "            descs_ref_enhanced = np.hstack((descs_ref_binary.astype(np.float32), descs_ref_color))\n",
    "            print(f\"  Reference: Enhanced descriptors shape: {descs_ref_enhanced.shape}\")\n",
    "        else:\n",
    "            print(\"  Reference: No binary descriptors computed.\")\n",
    "            keylines_ref = keylines_raw_ref # Keep raw keylines if no descriptors\n",
    "    else:\n",
    "        print(\"  Reference: No raw lines detected.\")\n",
    "    print(\"Finished processing reference image.\")\n",
    "else:\n",
    "    print(\"Reference image (img2_gray or img2_orig) not loaded. Skipping reference processing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73387b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- (Optional) Plot Detected Lines ---\n",
    "# This cell shows lines on the 1.0x scaled template and the reference image.\n",
    "\n",
    "if processed_templates_data and keylines_ref:\n",
    "    # Find the 1.0x scaled template data\n",
    "    template_1x_data = next((t for t in processed_templates_data if t['scale'] == 1.0), None)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    \n",
    "    # Plot lines on the 1.0x template\n",
    "    if template_1x_data and template_1x_data['keylines']:\n",
    "        ax1 = axes[0]\n",
    "        img_to_show_template = cv2.cvtColor(template_1x_data['image_bgr'], cv2.COLOR_BGR2RGB)\n",
    "        ax1.imshow(img_to_show_template)\n",
    "        ax1.set_title(f'Template (1.0x scale) with Detected Lines ({len(template_1x_data[\"keylines\"])})')\n",
    "        ax1.axis('off')\n",
    "        for kl in template_1x_data['keylines']:\n",
    "            pt1 = (kl.startPointX, kl.startPointY)\n",
    "            pt2 = (kl.endPointX, kl.endPointY)\n",
    "            ax1.plot([pt1[0], pt2[0]], [pt1[1], pt2[1]], color='lime', linewidth=1)\n",
    "    else:\n",
    "        axes[0].set_title('Template (1.0x scale) - No lines or data')\n",
    "        axes[0].axis('off')\n",
    "\n",
    "    # Plot lines on the reference image\n",
    "    ax2 = axes[1]\n",
    "    img_to_show_ref = cv2.cvtColor(img2_orig, cv2.COLOR_BGR2RGB)\n",
    "    ax2.imshow(img_to_show_ref)\n",
    "    ax2.set_title(f'Reference Image with Detected Lines ({len(keylines_ref)})')\n",
    "    ax2.axis('off')\n",
    "    if keylines_ref:\n",
    "        for kl in keylines_ref:\n",
    "            pt1 = (kl.startPointX, kl.startPointY)\n",
    "            pt2 = (kl.endPointX, kl.endPointY)\n",
    "            ax2.plot([pt1[0], pt2[0]], [pt1[1], pt2[1]], color='lime', linewidth=1)\n",
    "            \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not enough data to plot detected lines (template or reference lines missing).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f2e0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Matching, Filtering, and Scoring ---\n",
    "\n",
    "all_match_results = []\n",
    "\n",
    "if descs_ref_enhanced is not None and len(descs_ref_enhanced) > 0 and processed_templates_data:\n",
    "    print(\"Starting matching process across template scales...\")\n",
    "    for template_data in processed_templates_data:\n",
    "        current_scale = template_data['scale']\n",
    "        descs_template_current = template_data['descriptors_enhanced']\n",
    "        keylines_template_current = template_data['keylines']\n",
    "        \n",
    "        if descs_template_current is None or len(descs_template_current) == 0 or \\\n",
    "           keylines_template_current is None or len(keylines_template_current) == 0:\n",
    "            print(f\"  Skipping scale {current_scale}x: No descriptors or keylines for template.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"  Matching against template scale: {current_scale}x\")\n",
    "        \n",
    "        # 1. Raw matching using BDM (Binary Descriptor Matcher)\n",
    "        # Query descriptors first (reference), then train descriptors (template)\n",
    "        raw_matches = bdm.match(descs_ref_enhanced, descs_template_current)\n",
    "        print(f\"    Scale {current_scale}x: Found {len(raw_matches)} raw matches.\")\n",
    "\n",
    "        # 2. Filter by initial Hamming distance (optional, can be generous)\n",
    "        # This step is similar to the original notebook's \"good_matches\"\n",
    "        # It can help reduce the number of matches before more expensive geometric filtering.\n",
    "        distance_filtered_matches = [m for m in raw_matches if m.distance < MATCHES_DIST_THRESHOLD]\n",
    "        print(f\"    Scale {current_scale}x: {len(distance_filtered_matches)} matches after distance threshold (< {MATCHES_DIST_THRESHOLD}).\")\n",
    "        \n",
    "        # 3. Geometric Filtering\n",
    "        geometrically_filtered_matches = filter_matches_geometrically(\n",
    "            distance_filtered_matches,\n",
    "            keylines_ref,\n",
    "            keylines_template_current,\n",
    "            current_scale, # Pass the template's current scale factor\n",
    "            ANGLE_TOLERANCE_DEG,\n",
    "            LENGTH_RATIO_MIN,\n",
    "            LENGTH_RATIO_MAX\n",
    "        )\n",
    "        print(f\"    Scale {current_scale}x: {len(geometrically_filtered_matches)} matches after geometric filtering.\")\n",
    "\n",
    "        # 4. Calculate score (e.g., number of good matches, possibly weighted by scale)\n",
    "        # Reference code uses: len(valid_matches) * max(0.5, 1/scale)\n",
    "        # This gives higher scores to smaller scale templates if they achieve same number of matches.\n",
    "        score = len(geometrically_filtered_matches) * max(0.5, 1.0 / current_scale if current_scale > 1e-6 else 1.0)\n",
    "        \n",
    "        all_match_results.append({\n",
    "            'scale': current_scale,\n",
    "            'matches': geometrically_filtered_matches,\n",
    "            'score': score,\n",
    "            'template_keylines': keylines_template_current,\n",
    "            'template_image_bgr': template_data['image_bgr'] # For drawing\n",
    "        })\n",
    "        \n",
    "    # Sort results by score in descending order\n",
    "    if all_match_results:\n",
    "        all_match_results.sort(key=lambda x: x['score'], reverse=True)\n",
    "        print(\"\\nMatching results sorted by score:\")\n",
    "        for res in all_match_results:\n",
    "            print(f\"  Scale {res['scale']}x: Score = {res['score']:.2f}, Matches = {len(res['matches'])}\")\n",
    "    else:\n",
    "        print(\"No match results obtained.\")\n",
    "        \n",
    "else:\n",
    "    print(\"Cannot proceed with matching: Reference descriptors or processed template data is missing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fff2ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Display Best Match ---\n",
    "\n",
    "if all_match_results:\n",
    "    best_result = all_match_results[0]\n",
    "    print(f\"\\nBest result from scale: {best_result['scale']}x with score: {best_result['score']:.2f} and {len(best_result['matches'])} matches.\")\n",
    "\n",
    "    # Prepare for drawing\n",
    "    best_matches_to_draw = best_result['matches'][:MAX_MATCHES_TO_DISPLAY]\n",
    "    \n",
    "    # Reference image (query)\n",
    "    img_ref_draw = img2_orig.copy() \n",
    "    # Template image at the best scale\n",
    "    img_template_draw = best_result['template_image_bgr'].copy() \n",
    "\n",
    "    keylines_ref_for_draw = keylines_ref\n",
    "    keylines_template_for_draw = best_result['template_keylines']\n",
    "\n",
    "    # Create a combined image to draw matches\n",
    "    h1, w1 = img_template_draw.shape[:2]\n",
    "    h2, w2 = img_ref_draw.shape[:2]\n",
    "    \n",
    "    # Create a new canvas for combined image\n",
    "    # Ensure consistent height for side-by-side display\n",
    "    max_height = max(h1, h2)\n",
    "    # Resize images to have same height if needed, maintaining aspect ratio\n",
    "    if h1 != max_height:\n",
    "        img_template_draw = cv2.resize(img_template_draw, (int(w1 * max_height / h1), max_height))\n",
    "        w1 = img_template_draw.shape[1] # Update width\n",
    "    if h2 != max_height:\n",
    "        img_ref_draw = cv2.resize(img_ref_draw, (int(w2 * max_height / h2), max_height))\n",
    "        # w2 is not needed for offset if query is on the left\n",
    "\n",
    "    # Combined image: Reference on left, Template on right\n",
    "    # This is different from original notebook's template|reference. Let's do template|reference.\n",
    "    # Template on left (img_template_draw), Reference on right (img_ref_draw)\n",
    "    \n",
    "    # Update dimensions after potential resize\n",
    "    h1, w1 = img_template_draw.shape[:2]\n",
    "    h2, w2 = img_ref_draw.shape[:2]\n",
    "    \n",
    "    # Ensure both images have the same height for clean concatenation\n",
    "    target_h = max(h1, h2)\n",
    "    if h1 < target_h:\n",
    "        img_template_draw = cv2.resize(img_template_draw, (int(w1 * target_h / h1), target_h))\n",
    "        w1 = img_template_draw.shape[1]\n",
    "    if h2 < target_h:\n",
    "        img_ref_draw = cv2.resize(img_ref_draw, (int(w2 * target_h / h2), target_h))\n",
    "        w2 = img_ref_draw.shape[1]\n",
    "\n",
    "\n",
    "    combined_img_width = w1 + w2\n",
    "    combined_img = np.zeros((target_h, combined_img_width, 3), dtype=np.uint8)\n",
    "    combined_img[:target_h, :w1] = img_template_draw\n",
    "    combined_img[:target_h, w1:w1+w2] = img_ref_draw\n",
    "\n",
    "    # Draw lines and connections\n",
    "    for match in best_matches_to_draw:\n",
    "        # queryIdx refers to reference image descriptors, trainIdx to template image descriptors\n",
    "        idx_ref = match.queryIdx \n",
    "        idx_template = match.trainIdx\n",
    "\n",
    "        if idx_template < len(keylines_template_for_draw) and idx_ref < len(keylines_ref_for_draw):\n",
    "            kl_template = keylines_template_for_draw[idx_template]\n",
    "            kl_ref = keylines_ref_for_draw[idx_ref]\n",
    "\n",
    "            # Points for template line (on the left part of combined_img)\n",
    "            pt1_template = (int(kl_template.startPointX), int(kl_template.startPointY))\n",
    "            pt2_template = (int(kl_template.endPointX), int(kl_template.endPointY))\n",
    "            cv2.line(combined_img, pt1_template, pt2_template, (0, 255, 255), 1) # Cyan for template lines\n",
    "\n",
    "            # Points for reference line (on the right part, so X needs offset w1)\n",
    "            pt1_ref = (int(kl_ref.startPointX) + w1, int(kl_ref.startPointY))\n",
    "            pt2_ref = (int(kl_ref.endPointX) + w1, int(kl_ref.endPointY))\n",
    "            cv2.line(combined_img, pt1_ref, pt2_ref, (0, 255, 0), 1) # Lime for reference lines\n",
    "            \n",
    "            # Draw connecting line between start points (or midpoints)\n",
    "            # Using start points for this example\n",
    "            cv2.line(combined_img, pt1_template, pt1_ref, (255, 0, 0), 1) # Red connecting lines\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.imshow(cv2.cvtColor(combined_img, cv2.COLOR_BGR2RGB))\n",
    "    title_str = (f\"Best Matches (Scale {best_result['scale']}x, Score {best_result['score']:.2f}) - \"\n",
    "                 f\"Showing {len(best_matches_to_draw)} of {len(best_result['matches'])} geom. filtered matches\")\n",
    "    plt.title(title_str)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "elif processed_templates_data and descs_ref_enhanced is not None:\n",
    "    print(\"Matching process completed, but no suitable matches found across any scale after filtering.\")\n",
    "else:\n",
    "    print(\"Best match display skipped: No results from matching or prerequisites missing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ead99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- End of Notebook ---\n",
    "# Further analysis or parameter tuning can be done based on these results.\n",
    "# For example, exploring different scoring mechanisms, color descriptor variations,\n",
    "# or more advanced geometric verification (e.g., RANSAC-based homography)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
